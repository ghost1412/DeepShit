{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/amazon_cells_labelled.csv\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/amazon_cells_labelled.txt\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/imdb_labelled.csv\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/imdb_labelled.txt\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/readme.txt\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/yelp_labelled.csv\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/yelp_labelled.txt\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.csv\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/sentiment labelled sentences/amazon_cells_labelled.txt\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.csv\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/sentiment labelled sentences/imdb_labelled.txt\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/sentiment labelled sentences/readme.txt\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.csv\n",
      "/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/sentiment labelled sentences/yelp_labelled.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df=pd.read_csv(\"/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/amazon_cells_labelled.txt\",delimiter='\\t',\n",
    "                        header=None, \n",
    "                        names=['review', 'sentiment'])\n",
    "\n",
    "imdb_df = pd.read_csv(\"/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/imdb_labelled.txt\", \n",
    "                        delimiter='\\t', \n",
    "                        header=None, \n",
    "                        names=['review', 'sentiment'])\n",
    "\n",
    "yelp_df = pd.read_csv(\"/media/ghost/New Volume/dataset/sentiment-labelled-sentences-data-set/sentiment labelled sentences/yelp_labelled.txt\", \n",
    "                        delimiter='\\t', \n",
    "                        header=None, \n",
    "                        names=['review', 'sentiment'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "#from keras import initializations\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        #super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([amazon_df,yelp_df,imdb_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop='True',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What a waste of money and time!.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And the sound quality is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>He was very impressed when going from the orig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>If the two were seperated by a mere 5+ ft I st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Very good quality though</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The design is very odd, as the ear \"clip\" is n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Highly recommend for any one who has a blue to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I advise EVERYONE DO NOT BE FOOLED!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>So Far So Good!.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Works great!.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It clicks into place in a way that makes you w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I went on Motorola's website and followed all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I bought this to use with my Kindle Fire and a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The commercials are the most misleading.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I have yet to run this new battery below two b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I bought it for my mother and she had a proble...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Great Pocket PC / phone combination.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I've owned this phone for 7 months now and can...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I didn't think that the instructions provided ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>People couldnt hear me talk and I had to pull ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Doesn't hold charge.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>Enough can not be said of the remarkable anima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>The art style has the appearance of crayon/pen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>If you act in such a film, you should be glad ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>This one wants to surf on the small wave of sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>If you haven't choked in your own vomit by the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>Still, it makes up for all of this with a supe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>Just consider the excellent story, solid actin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>Instead, we got a bore fest about a whiny, spo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>Then I watched it again two Sundays ago (March...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>It is a very well acted and done TV Movie.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>Judith Light is one of my favorite actresses a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>I keep watching it over and over.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>It's a sad movie, but very good.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>If you have not seen this movie, I definitely ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>She is as lovely as usual, this cutie!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>Still it's quite interesting and entertaining ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>;) Recommend with confidence!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>This movie is well-balanced with comedy and dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>It was a riot to see Hugo Weaving play a sex-o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>:) Anyway, the plot flowed smoothly and the ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>The opening sequence of this gem is a classic,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>Fans of the genre will be in heaven.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>Lange had become a great actress.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>It looked like a wonderful story.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>I never walked out of a movie faster.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0     So there is no way for me to plug it in here i...          0\n",
       "1                           Good case, Excellent value.          1\n",
       "2                                Great for the jawbone.          1\n",
       "3     Tied to charger for conversations lasting more...          0\n",
       "4                                     The mic is great.          1\n",
       "5     I have to jiggle the plug to get it to line up...          0\n",
       "6     If you have several dozen or several hundred c...          0\n",
       "7           If you are Razr owner...you must have this!          1\n",
       "8                   Needless to say, I wasted my money.          0\n",
       "9                      What a waste of money and time!.          0\n",
       "10                      And the sound quality is great.          1\n",
       "11    He was very impressed when going from the orig...          1\n",
       "12    If the two were seperated by a mere 5+ ft I st...          0\n",
       "13                             Very good quality though          1\n",
       "14    The design is very odd, as the ear \"clip\" is n...          0\n",
       "15    Highly recommend for any one who has a blue to...          1\n",
       "16                  I advise EVERYONE DO NOT BE FOOLED!          0\n",
       "17                                     So Far So Good!.          1\n",
       "18                                        Works great!.          1\n",
       "19    It clicks into place in a way that makes you w...          0\n",
       "20    I went on Motorola's website and followed all ...          0\n",
       "21    I bought this to use with my Kindle Fire and a...          1\n",
       "22             The commercials are the most misleading.          0\n",
       "23    I have yet to run this new battery below two b...          1\n",
       "24    I bought it for my mother and she had a proble...          0\n",
       "25                 Great Pocket PC / phone combination.          1\n",
       "26    I've owned this phone for 7 months now and can...          1\n",
       "27    I didn't think that the instructions provided ...          0\n",
       "28    People couldnt hear me talk and I had to pull ...          0\n",
       "29                                 Doesn't hold charge.          0\n",
       "...                                                 ...        ...\n",
       "2718  Enough can not be said of the remarkable anima...          1\n",
       "2719  The art style has the appearance of crayon/pen...          1\n",
       "2720  If you act in such a film, you should be glad ...          0\n",
       "2721  This one wants to surf on the small wave of sp...          0\n",
       "2722  If you haven't choked in your own vomit by the...          0\n",
       "2723  Still, it makes up for all of this with a supe...          1\n",
       "2724  Just consider the excellent story, solid actin...          1\n",
       "2725  Instead, we got a bore fest about a whiny, spo...          0\n",
       "2726  Then I watched it again two Sundays ago (March...          1\n",
       "2727       It is a very well acted and done TV Movie.            1\n",
       "2728  Judith Light is one of my favorite actresses a...          1\n",
       "2729                I keep watching it over and over.            1\n",
       "2730                 It's a sad movie, but very good.            1\n",
       "2731  If you have not seen this movie, I definitely ...          1\n",
       "2732           She is as lovely as usual, this cutie!            1\n",
       "2733  Still it's quite interesting and entertaining ...          1\n",
       "2734                    ;) Recommend with confidence!            1\n",
       "2735  This movie is well-balanced with comedy and dr...          1\n",
       "2736  It was a riot to see Hugo Weaving play a sex-o...          1\n",
       "2737  :) Anyway, the plot flowed smoothly and the ma...          1\n",
       "2738  The opening sequence of this gem is a classic,...          1\n",
       "2739             Fans of the genre will be in heaven.            1\n",
       "2740                Lange had become a great actress.            1\n",
       "2741                It looked like a wonderful story.            1\n",
       "2742            I never walked out of a movie faster.            0\n",
       "2743  I just got bored watching Jessice Lange take h...          0\n",
       "2744  Unfortunately, any virtue in this film's produ...          0\n",
       "2745                   In a word, it is embarrassing.            0\n",
       "2746                               Exceptionally bad!            0\n",
       "2747  All in all its an insult to one's intelligence...          0\n",
       "\n",
       "[2748 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Reviews and Sentiments\n",
    "sentences=data['review'].tolist()\n",
    "label=data['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences\n",
      "So there is no way for me to plug it in here in the US unless I go by a converter. 0\n",
      "Good case, Excellent value. 1\n",
      "Great for the jawbone. 1\n",
      "Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!! 0\n",
      "The mic is great. 1\n",
      "I have to jiggle the plug to get it to line up right to get decent volume. 0\n",
      "If you have several dozen or several hundred contacts, then imagine the fun of sending each of them one by one. 0\n",
      "If you are Razr owner...you must have this! 1\n",
      "Needless to say, I wasted my money. 0\n",
      "What a waste of money and time!. 0\n"
     ]
    }
   ],
   "source": [
    "# print some examples of sentences and labels\n",
    "\n",
    "print(\"Sentences\")\n",
    "for i in range(10):\n",
    "    #print(sentences[i],end=\"\\n\")\n",
    "    print(\"{} {}\".format(sentences[i],label[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow==2.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (1.25.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /home/ghost/.local/lib/python3.7/site-packages (from tensorflow==2.0) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (0.33.4)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorflow==2.0) (3.10.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /home/ghost/.local/lib/python3.7/site-packages (from tensorflow==2.0) (1.17.4)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (41.0.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.15.4)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2020.4.5.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install -U \"tensorflow==2.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create A Subword Datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab_size=1000\n",
    "tokenizer=tfds.features.text.SubwordTextEncoder.build_from_corpus(sentences,vocab_size,max_subword_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is 1000\n",
      "Good case, Excellent value.\n",
      "[586, 485, 534, 2, 811, 862, 514, 678, 428, 165, 843, 788]\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size is\",vocab_size)\n",
    "\n",
    "#check the tokenizer words\n",
    "num=1\n",
    "print(sentences[num])\n",
    "encoded_sentence=tokenizer.encode(sentences[num])\n",
    "print(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go\n",
      "od \n",
      "case\n",
      ", \n",
      "E\n",
      "x\n",
      "cell\n",
      "ent \n",
      "va\n",
      "lu\n",
      "e\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for i in encoded_sentence:\n",
    "    print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sent in enumerate(sentences):\n",
    "    sentences[i]=tokenizer.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[346, 774, 164, 774, 7, 217, 539, 23, 141, 9, 854, 165, 36, 18, 19, 281, 19, 1, 827, 825, 774, 56, 488, 6, 292, 192, 5, 119, 124, 236, 788]\n",
      "[586, 485, 534, 2, 811, 862, 514, 678, 428, 165, 843, 788]\n",
      "[305, 774, 23, 1, 848, 219, 104, 49, 788]\n",
      "[826, 239, 14, 9, 344, 93, 23, 119, 124, 65, 405, 3, 47, 110, 20, 271, 215, 794, 738, 505, 126, 788, 819, 807, 816, 821, 824, 774, 822, 824, 821, 808, 818, 811, 819, 825, 740]\n",
      "[15, 384, 362, 7, 51, 788]\n",
      "[6, 43, 9, 848, 259, 415, 17, 1, 854, 165, 36, 9, 226, 18, 9, 604, 774, 254, 569, 774, 9, 226, 55, 37, 145, 152, 165, 111, 788]\n",
      "[373, 48, 43, 39, 686, 52, 310, 500, 30, 105, 39, 686, 52, 394, 218, 298, 774, 533, 173, 857, 2, 689, 774, 205, 559, 459, 774, 1, 395, 774, 12, 692, 629, 774, 177, 250, 12, 668, 63, 192, 527, 788]\n",
      "[373, 48, 41, 824, 839, 864, 25, 671, 84, 640, 48, 437, 8, 43, 544, 857, 775]\n",
      "[820, 240, 842, 488, 9, 65, 863, 2, 6, 480, 14, 32, 674, 788]\n",
      "[423, 54, 5, 480, 774, 12, 674, 774, 4, 184, 611]\n"
     ]
    }
   ],
   "source": [
    "#print some encoded text\n",
    "for i in range(10):\n",
    "    print(sentences[i],end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_length =50\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "\n",
    "#pad all Sequence\n",
    "\n",
    "sequence_added=pad_sequences(sentences,maxlen=max_length,padding =padding_type,truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the separate and Sentences on training and test data sets\n",
    "\n",
    "training_size=int(len(sentences)*0.8)\n",
    "train_seq=sequence_added[:training_size]\n",
    "train_labels=label[:training_size]\n",
    "\n",
    "test_seq=sequence_added[training_size:]\n",
    "test_labels=label[training_size:]\n",
    "\n",
    "train_labels=np.array(train_labels)\n",
    "test_labels=np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of Training Sequence are 2198\n",
      "Total no of Test Sequence are 550\n"
     ]
    }
   ],
   "source": [
    "print(\"Total no of Training Sequence are\",len(train_seq))\n",
    "print(\"Total no of Test Sequence are\",len(test_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The added layer must be an instance of class Layer. Found: <__main__.AttentionWithContext object at 0x7fb24ed22828>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-34e989664970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttentionWithContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ghost/71f17ea4-f157-44e3-8ec8-4d543ed39935/home/gh05t/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    156\u001b[0m       raise TypeError('The added layer must be '\n\u001b[1;32m    157\u001b[0m                       \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                       'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: <__main__.AttentionWithContext object at 0x7fb24ed22828>"
     ]
    }
   ],
   "source": [
    "#Create a Model\n",
    "embedding_dim=16\n",
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim,return_sequences=True)))\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)))\n",
    "model.add(AttentionWithContext())\n",
    "model.add(tf.keras.layers.Dense(6,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a model\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_seq,train_labels,epochs=50,validation_data=(test_seq,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "        plt.plot(history.history[string])\n",
    "        plt.plot(history.history['val_'+string])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(string)\n",
    "        plt.legend([string, 'val_'+string])\n",
    "        plt.show()\n",
    "\n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(model, new_sentences, maxlen=max_length, show_padded_sequence=True ):\n",
    "    # Keep the original sentences so that we can keep using them later\n",
    "    # Create an array to hold the encoded sequences\n",
    "    new_sequences = []\n",
    "\n",
    "    # Convert the new reviews to sequences\n",
    "    for i, frvw in enumerate(new_sentences):\n",
    "        new_sequences.append(tokenizer.encode(frvw))\n",
    "\n",
    "    trunc_type='post' \n",
    "    padding_type='post'\n",
    "\n",
    "    # Pad all sequences for the new reviews\n",
    "    new_reviews_padded = pad_sequences(new_sequences, maxlen=max_length, \n",
    "                                 padding=padding_type, truncating=trunc_type)             \n",
    "\n",
    "    classes = model.predict(new_reviews_padded)\n",
    "\n",
    "    # The closer the class is to 1, the more positive the review is\n",
    "    for x in range(len(new_sentences)):\n",
    "\n",
    "        # We can see the padded sequence if desired\n",
    "        # Print the sequence\n",
    "        if (show_padded_sequence):\n",
    "              print(new_reviews_padded[x])\n",
    "        # Print the review as text\n",
    "        print(new_sentences[x])\n",
    "        # Print its predicted class\n",
    "        print(classes[x])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict some reviews   \n",
    "fake_reviews = [\"I love this phone\", \n",
    "                \"Everything was cold\",\n",
    "                \"Everything was hot exactly as I wanted\", \n",
    "                \"Everything was green\", \n",
    "                \"the host seated us immediately\",\n",
    "                \"they gave us free chocolate cake\", \n",
    "                \"we couldn't hear each other talk because of the shouting in the kitchen\"\n",
    "              ]\n",
    "\n",
    "predict_review(model, fake_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
